#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <stdbool.h>
#include <float.h>

// ================== Layer: fc1 ================== //
// Transposed weights for layer: fc1 @5x10;
float fc1_weight_transposed[50] = {0.43823242, -0.31762695, 0.36450195, -0.40087891, -0.18847656, 0.12219238, 0.18310547, -0.43286133, -0.08288574, 0.18457031, -0.11578369, -0.08355713, -0.36450195, -0.33544922, 0.44238281, 0.09320068, 0.20495605, -0.35571289, 0.37133789, 0.43457031, -0.12115479, 0.16918945, -0.29174805, -0.42407227, 0.12963867, 0.18005371, -0.18652344, 0.39941406, -0.38159180, 0.15905762, 0.29956055, 0.36816406, 0.02250671, -0.02270508, -0.16467285, -0.07519531, 0.31616211, 0.22558594, -0.05020142, -0.17858887, 0.42895508, 0.27880859, -0.43896484, -0.42553711, 0.03099060, -0.31079102, 0.06274414, 0.01222992, 0.12353516, 0.22094727};
// Biases for layer: fc1 @10;
float fc1_bias_transposed[10] = {0.35815430, 0.33789062, 0.16320801, 0.44653320, 0.03576660, -0.05706787, 0.15222168, -0.16772461, 0.31542969, 0.03668213};

// ================== Relu: relu1 ================== //
// Relu for layer: relu1;

// ================== Dropout: dropout1 ================== //
// Dropout for layer: dropout1;

// ================== Layer: fc2 ================== //
// Transposed weights for layer: fc2 @10x20;
float fc2_weight_transposed[200] = {0.27124023, 0.18041992, 0.11633301, -0.27246094, -0.15576172, -0.25708008, 0.18432617, -0.12744141, 0.24121094, 0.11926270, -0.23522949, 0.20593262, 0.20922852, 0.24987793, 0.03146362, 0.15209961, 0.05963135, 0.23242188, 0.01182556, 0.27490234, -0.07849121, -0.08746338, -0.18395996, 0.29101562, -0.04287720, -0.17895508, 0.12274170, -0.01681519, 0.02357483, 0.02276611, -0.28344727, -0.20971680, -0.08630371, -0.10516357, -0.28735352, -0.23376465, -0.05871582, -0.18530273, -0.18212891, 0.13269043, -0.21569824, 0.13391113, 0.28442383, 0.08129883, -0.26049805, 0.26196289, 0.23742676, -0.30517578, -0.22412109, -0.04602051, -0.05236816, 0.15234375, 0.05426025, -0.27685547, -0.26147461, 0.00019240, 0.26171875, -0.18017578, 0.20751953, 0.09747314, -0.16162109, -0.11499023, 0.29956055, -0.27343750, -0.11309814, -0.09527588, 0.20739746, -0.09790039, -0.15991211, -0.02474976, -0.09436035, 0.21728516, 0.18103027, 0.26611328, 0.19055176, -0.17956543, 0.14965820, -0.06512451, 0.01002502, 0.31030273, -0.10058594, 0.15515137, 0.20715332, 0.19506836, 0.10028076, -0.31616211, 0.21240234, -0.30322266, 0.22766113, -0.29223633, -0.02896118, -0.20043945, -0.02282715, -0.16992188, 0.23132324, 0.09350586, 0.09014893, -0.14624023, 0.02084351, 0.20373535, 0.22082520, -0.06774902, -0.22497559, 0.04092407, -0.28588867, -0.10778809, 0.25854492, 0.23291016, 0.02323914, -0.24658203, 0.04150391, -0.30297852, -0.19360352, 0.22814941, -0.09710693, 0.14111328, -0.26025391, -0.08947754, -0.00096846, -0.29028320, -0.24853516, 0.22668457, -0.10321045, 0.15405273, 0.26586914, -0.19018555, 0.00106335, -0.04226685, 0.31347656, -0.09289551, -0.09570312, 0.01872253, -0.24414062, 0.17236328, -0.06082153, -0.22155762, -0.10424805, 0.07855225, -0.23291016, -0.07635498, 0.09912109, -0.31274414, -0.28149414, -0.12658691, -0.07562256, -0.15466309, 0.25000000, 0.30224609, -0.04840088, 0.30737305, -0.15026855, 0.01303864, -0.29833984, -0.04446411, 0.06094360, 0.04733276, -0.08135986, -0.22912598, 0.18688965, -0.16955566, -0.07403564, -0.25927734, 0.22644043, -0.02172852, 0.22912598, 0.20446777, -0.26879883, 0.05718994, -0.15686035, 0.20507812, 0.20422363, 0.09765625, -0.19372559, -0.05728149, 0.27172852, -0.21887207, 0.25463867, 0.24572754, -0.04025269, -0.16308594, -0.22326660, -0.14965820, -0.30346680, -0.12597656, -0.26635742, 0.16479492, -0.08587646, -0.23168945, 0.23071289, 0.16833496, -0.12622070, 0.01014709, 0.04562378, 0.18640137, -0.07659912, -0.03857422, 0.19360352, 0.18066406, -0.12951660, 0.04559326};
// Biases for layer: fc2 @20;
float fc2_bias_transposed[20] = {-0.13391113, -0.16687012, 0.27685547, 0.27124023, 0.01004791, 0.06652832, -0.13256836, -0.13415527, 0.04910278, 0.12066650, 0.13110352, 0.10443115, -0.06414795, 0.01122284, 0.14099121, 0.23193359, -0.28491211, -0.00804901, 0.19360352, -0.07452393};

// ================== Dropout: dropout2 ================== //
// Dropout for layer: dropout2;

// ================== Layer: fc5 ================== //
// Transposed weights for layer: fc5 @20x3;
float fc5_weight_transposed[60] = {0.12817383, 0.15649414, 0.04409790, 0.12078857, -0.21508789, -0.00716782, 0.16259766, 0.14257812, -0.01541901, 0.02554321, -0.14526367, 0.02745056, 0.08264160, 0.17797852, -0.12249756, 0.13586426, -0.15380859, 0.19372559, 0.17871094, 0.19641113, 0.03271484, -0.14038086, 0.08349609, 0.03195190, -0.21875000, 0.04217529, -0.00749588, -0.00629807, -0.15966797, 0.14636230, 0.08905029, 0.17834473, 0.03198242, -0.16442871, 0.07659912, 0.08551025, 0.10180664, 0.08367920, -0.09051514, -0.09088135, -0.10485840, 0.07629395, 0.06652832, -0.17199707, 0.10784912, -0.11682129, -0.20544434, 0.10870361, 0.05139160, 0.06469727, 0.01977539, 0.03057861, -0.04864502, -0.19409180, 0.14355469, -0.11535645, -0.11529541, 0.04367065, -0.19226074, 0.08032227};
// Biases for layer: fc5 @3;
float fc5_bias_transposed[3] = {-0.19250488, 0.15856934, -0.16357422};

// ================== SoftMax: softmax2 ================== //
// SoftMax for layer: softmax2;

float *Linear(int batch_size, int input_size, int output_size, float *input, float *weight_transposed, float *bias)
{
    int i, j, k;

    // 为结果矩阵分配内存
    float *result = (float *)malloc(batch_size * output_size * sizeof(float));
    if (result == NULL)
    {
        printf("Error: Memory allocation failed.\n");
        return NULL;
    }

    // 初始化并执行矩阵乘法
    for (i = 0; i < batch_size; i++)
    {
        for (j = 0; j < output_size; j++)
        {
            result[i * output_size + j] = 0; // 初始化元素为0
            for (k = 0; k < input_size; k++)
            {
                result[i * output_size + j] += input[i * input_size + k] * weight_transposed[k * output_size + j];
            }
            result[i * output_size + j] += bias[j]; // 将偏置项加到结果中
        }
    }

    // 返回结果矩阵
    return result;
}
void Relu(int batch_size, int elements_length, float *input)
{
    for (int i = 0; i < batch_size * elements_length; i++)
    {
        if (input[i] < 0)
        {
            input[i] = 0;
        }
    }
}
void SoftMax(int batch_size, int elements_length, float *input)
{
    float max_value, sum_exp;

    // 逐行计算softmax
    for (int i = 0; i < batch_size; i++)
    {
        // 找到该行的最大值
        max_value = input[i * elements_length];
        for (int j = 1; j < elements_length; j++)
        {
            if (input[i * elements_length + j] > max_value)
            {
                max_value = input[i * elements_length + j];
            }
        }

        // 计算该行的指数和
        sum_exp = 0.0f;
        for (int j = 0; j < elements_length; j++)
        {
            input[i * elements_length + j] = exp(input[i * elements_length + j] - max_value);
            sum_exp += input[i * elements_length + j];
        }

        // 归一化得到softmax输出
        for (int j = 0; j < elements_length; j++)
        {
            input[i * elements_length + j] /= sum_exp;
        }
    }
}

float* forward(float input[], float output[]){
	float* result_0=(float*)malloc(sizeof(float)*5);
for (int i = 0; i < 5; i++) { result_0[i] = input[i]; }
// fc1_layer
float* result_1 = Linear(1,5,10,result_0,fc1_weight_transposed,fc1_bias_transposed);
free(result_0);
// relu1_relu
Relu(1,10,result_1);
// dropout1_layer
// fc2_layer
float* result_2 = Linear(1,10,20,result_1,fc2_weight_transposed,fc2_bias_transposed);
free(result_1);
// dropout2_layer
// fc5_layer
float* result_3 = Linear(1,20,3,result_2,fc5_weight_transposed,fc5_bias_transposed);
free(result_2);
// softmax2_layer
SoftMax(1,3,result_3);
for (int i = 0; i < 3; i++) { output[i] = result_3[i]; }
	free(result_3);
}
int main(){
float input[5] = { 0.12004818022251129,0.47743451595306396,1.3396046161651611,-0.05327654629945755,-0.222962886095047 };
float output[3];
forward(input, output);
for (int i = 0; i < 3; i++){ printf("%f  ", output[i]); 
 }
return 0;
}